---
category: "19-Reference"
fetched_at: "2026-02-08T23:10:02Z"
source_url: "https://www.anthropic.com/news/anthropic-raises-series-b-to-build-safe-reliable-ai"
title: "Anthropic Raises Series B to build steerable, interpretable, robust AI systems \\ Anthropic"
---

Announcements

# Anthropic Raises Series B to build steerable, interpretable, robust AI systems

Apr 29, 2022

Anthropic, an AI safety and research company, has raised \$580 million in a Series B. The financing will help Anthropic build large-scale experimental infrastructure to explore and improve the safety properties of computationally intensive AI models.  
  
Since its founding at the beginning of 2021, Anthropic has conducted research into making systems that are more steerable, robust, and interpretable. On interpretability, it has made progress in mathematically [reverse engineering the behavior of small language models](https://transformer-circuits.pub/2021/framework/index.html) and begun to understand the source of [pattern-matching behavior in large language models](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html). On steerability and robustness, it has developed [baseline techniques to make large language models more “helpful and harmless”](https://arxiv.org/abs/2112.00861), and followed this up with [reinforcement learning to further improve these properties](https://arxiv.org/abs/2204.05862), as well as releasing a dataset to help other research labs train models that are more [aligned with human preferences](https://github.com/anthropics/hh-rlhf). It has also released an analysis of [sudden changes in performance in large language models and the societal impacts of this phenomenon](https://arxiv.org/abs/2202.07785), which demonstrates the need for studying safety issues at scale.  
  
The purpose of this research is to develop the technical components necessary to build large-scale models which have better implicit safeguards and require less after-training interventions, as well as to develop the tools necessary to further look inside these models to be confident that the safeguards actually work. The company is also building out teams and partnerships dedicated to exploring the policy and societal impacts of these models.  
  
“With this fundraise, we’re going to explore the predictable scaling properties of machine learning systems, while closely examining the unpredictable ways in which capabilities and safety issues can emerge at-scale,” said Anthropic co-founder and CEO Dario Amodei. “We’ve made strong initial progress on understanding and steering the behavior of AI systems, and are gradually assembling the pieces needed to make usable, integrated AI systems that benefit society.”  
  
Anthropic is now a growing team of around 40 people based in a plant-filled office in San Francisco, California, with plans to expand further this year. “Now that we’ve built out the organization, we’re focusing on ensuring Anthropic has the culture and governance to continue to responsibly explore and develop safe AI systems as we scale,” said Anthropic co-founder and President Daniela Amodei. “We’re excited about what’s ahead, and grateful to all be working together.”  
  
The Series B follows the company raising \$124 million in a Series A round in 2021. The Series B round was led by Sam Bankman-Fried, CEO of FTX. The round also included participation from Caroline Ellison, Jim McClave, Nishad Singh, Jaan Tallinn, and the Center for Emerging Risk Research (CERR).

[](https://twitter.com/intent/tweet?text=https://www.anthropic.com/news/anthropic-raises-series-b-to-build-safe-reliable-ai)[](https://www.linkedin.com/shareArticle?mini=true&url=https://www.anthropic.com/news/anthropic-raises-series-b-to-build-safe-reliable-ai)

## Related content

### Introducing Claude Opus 4.6

We’re upgrading our smartest model. Across agentic coding, computer use, tool use, search, and finance, Opus 4.6 is an industry-leading model, often by wide margin.

[Read more](/news/claude-opus-4-6)

### Claude is a space to think

We’ve made a choice: Claude will remain ad-free. We explain why advertising incentives are incompatible with a genuinely helpful AI assistant, and how we plan to expand access without compromising user trust.

[Read more](/news/claude-is-a-space-to-think)

### Apple’s Xcode now supports the Claude Agent SDK

[Read more](/news/apple-xcode-claude-agent-sdk)
