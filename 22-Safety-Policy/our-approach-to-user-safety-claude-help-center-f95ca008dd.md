---
category: "22-Safety-Policy"
fetched_at: "2026-02-10T10:49:37Z"
source_url: "https://support.claude.com/en/articles/8106465-our-approach-to-user-safety"
title: "Our Approach to User Safety | Claude Help Center"
---

[](/en/)

[API Docs](https://docs.claude.com/en/docs/intro)[Release Notes](https://support.claude.com/en/articles/12138966-release-notes)[How to Get Support](https://support.claude.com/en/articles/9015913-how-to-get-support)

EnglishFranÃ§aisDeutschBahasa IndonesiaItalianoæ—¥æœ¬èªí•œêµ­ì–´PortuguÃªsPÑƒÑÑĞºĞ¸Ğ¹ç®€ä½“ä¸­æ–‡EspaÃ±olç¹é«”ä¸­æ–‡

English

[API Docs](https://docs.claude.com/en/docs/intro)[Release Notes](https://support.claude.com/en/articles/12138966-release-notes)[How to Get Support](https://support.claude.com/en/articles/9015913-how-to-get-support)

EnglishFranÃ§aisDeutschBahasa IndonesiaItalianoæ—¥æœ¬èªí•œêµ­ì–´PortuguÃªsPÑƒÑÑĞºĞ¸Ğ¹ç®€ä½“ä¸­æ–‡EspaÃ±olç¹é«”ä¸­æ–‡

English

Search for articles...

[All Collections](/en/)

[Safeguards](https://support.claude.com/en/collections/4078535-safeguards)

Our Approach to User Safety

# Our Approach to User Safety

Updated this week

User safety is core to Anthropicâ€™s mission of creating reliable, interpretable, and steerable AI systems. As we launch new ways for people to interact with Claude, we also expect to see new types of potential harm materialize, whether through the generation of misinformation, objectionable content, hate speech or other misuses. We are actively investing in and experimenting with additional safety features to supplement our existing model safety efforts and are working to provide helpful tools to a wide audience while also doing our best to mitigate harm. Launching new products in open beta allows us to experiment, iterate and hear your feedback. Here are some of the safety features weâ€™ve introduced:

- Detection models that flag potentially harmful content based on our [Usage Policy](https://vault.pactsafe.io/s/9f502c93-cb5c-4571-b205-1e479da61794/legal.html#aup).

- Safety filters on prompts, which may block responses from the model when our detection models flag content as harmful.

- Enhanced safety filters, which allow us to increase the sensitivity of our detection models. We may temporarily apply enhanced safety filters to users who repeatedly violate our policies, and remove these controls after a period of no or few violations.

These features are not failsafe, and we may make mistakes through false positives or false negatives. Your feedback on these measures and how we explain them to users will play a key role in helping us improve these safety systems, and we encourage you to reach out to us at [\[emailÂ protected\]](/cdn-cgi/l/email-protection#4d383e283f3e2c2b2839340d2c2339253f223d242e632e2220) with any feedback you may have. To learn more, [read about our core views on AI safety](https://www.anthropic.com/index/core-views-on-ai-safety).

------------------------------------------------------------------------

Related Articles

[](https://support.claude.com/en/articles/7996906-reporting-blocking-and-removing-content-from-claude)

Reporting, Blocking, and Removing Content from Claude

[](https://support.claude.com/en/articles/8241216-i-m-planning-to-launch-a-product-using-the-claude-api-what-steps-should-i-take-to-ensure-i-m-not-violating-anthropic-s-usage-policy)

Iâ€™m planning to launch a product using the Claude API. What steps should I take to ensure Iâ€™m not violating Anthropicâ€™s Usage Policy?

[](https://support.claude.com/en/articles/9020328-csam-detection-and-reporting)

CSAM Detection and Reporting

[](https://support.claude.com/en/articles/9199617-api-safeguards-tools)

API Safeguards Tools

[](https://support.claude.com/en/articles/10684638-reporting-blocking-and-removing-content-from-claude)

Reporting, Blocking, and Removing Content from Claude

Did this answer your question?

ğŸ˜

ğŸ˜

ğŸ˜ƒ

[](/en/)

- [Product](https://www.anthropic.com/product)
- [Research](https://www.anthropic.com/research)
- [Company](https://www.anthropic.com/company)
- [News](https://www.anthropic.com/news)
- [Careers](https://www.anthropic.com/careers)

- [Terms of Service - Consumer](https://www.anthropic.com/terms)
- [Terms of Service - Commercial](https://www.anthropic.com/legal/commercial-terms)
- [Privacy Policy](https://www.anthropic.com/privacy)
- [Usage Policy](https://www.anthropic.com/aup)
- [Responsible Disclosure Policy](https://www.anthropic.com/responsible-disclosure-policy)
- [Compliance](https://trust.anthropic.com/)
