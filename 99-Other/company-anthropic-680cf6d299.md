---
category: "99-Other"
fetched_at: "2026-02-10T10:49:12Z"
last_modified: "Mon, 09 Feb 2026 17:04:41 GMT"
source_url: "https://www.anthropic.com/company"
title: "Company \\ Anthropic"
---

[](#main)

Skip to main content

[](#footer)

Skip to footer

[](https://www.anthropic.com/)

- [](https://www.anthropic.com/research)
  Research

- [](https://www.anthropic.com/economic-futures)
  Economic Futures

- Commitments

  Initiatives

  - [](https://www.anthropic.com/constitution)
    Claude's Constitution
  - [](https://www.anthropic.com/transparency)
    Transparency
  - [](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)
    Responsible Scaling Policy

  Trust center

  - [](http://trust.anthropic.com/)
    Security and compliance

- Learn

  Learn

  - [](https://www.anthropic.com/learn)
    Anthropic Academy
  - [](https://claude.com/resources/tutorials)
    Tutorials
  - [](https://claude.com/resources/use-cases)
    Use cases
  - [](https://www.anthropic.com/engineering)
    Engineering at Anthropic
  - [](https://docs.claude.com)
    Developer docs

  Company

  - [](https://www.anthropic.com/company)
    About
  - [](https://www.anthropic.com/careers)
    Careers
  - [](https://www.anthropic.com/events)
    Events

- [](https://www.anthropic.com/news)
  News

- [Try Claude](https://claude.ai)
  Try Claude

  Try Claude

  Learn more about Claude

  Products

  - [](https://claude.com/product/overview)
    Claude
  - [](https://claude.com/product/claude-code)
    Claude Code
  - [](https://claude.com/platform/api)
    Claude Developer Platform
  - [](https://claude.com/pricing)
    Pricing
  - [](https://claude.com/contact-sales)
    Contact sales

  Models

  - [](https://www.anthropic.com/claude/opus)
    Opus
  - [](https://www.anthropic.com/claude/sonnet)
    Sonnet
  - [](https://www.anthropic.com/claude/haiku)
    Haiku

  Log in

  - [](https://claude.ai/login)
    Claude.ai
  - [](https://platform.claude.com/)
    Claude Console

&nbsp;

- EN

  [](#)
  This is some text inside of a div block.

- [Log in to Claude](https://claude.ai/login)
  Log in to Claude

  Log in to Claude

  [Download app](https://claude.ai/download)
  Download app

  Download app

[](https://www.anthropic.com/)

- [](https://www.anthropic.com/research)
  Research

- [](https://www.anthropic.com/economic-futures)
  Economic Futures

- Commitments

  Initiatives

  - [](https://www.anthropic.com/constitution)
    Claude's Constitution
  - [](https://www.anthropic.com/transparency)
    Transparency
  - [](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)
    Responsible Scaling Policy

  Trust center

  - [](http://trust.anthropic.com/)
    Security and compliance

- Learn

  Learn

  - [](https://www.anthropic.com/learn)
    Anthropic Academy
  - [](https://claude.com/resources/tutorials)
    Tutorials
  - [](https://claude.com/resources/use-cases)
    Use cases
  - [](https://www.anthropic.com/engineering)
    Engineering at Anthropic
  - [](https://docs.claude.com)
    Developer docs

  Company

  - [](https://www.anthropic.com/company)
    About
  - [](https://www.anthropic.com/careers)
    Careers
  - [](https://www.anthropic.com/events)
    Events

- [](https://www.anthropic.com/news)
  News

- [Try Claude](https://claude.ai)
  Try Claude

  Try Claude

  Learn more about Claude

  Products

  - [](https://claude.com/product/overview)
    Claude
  - [](https://claude.com/product/claude-code)
    Claude Code
  - [](https://claude.com/platform/api)
    Claude Developer Platform
  - [](https://claude.com/pricing)
    Pricing
  - [](https://claude.com/contact-sales)
    Contact sales

  Models

  - [](https://www.anthropic.com/claude/opus)
    Opus
  - [](https://www.anthropic.com/claude/sonnet)
    Sonnet
  - [](https://www.anthropic.com/claude/haiku)
    Haiku

  Log in

  - [](https://claude.ai/login)
    Claude.ai
  - [](https://platform.claude.com/)
    Claude Console

&nbsp;

- EN

  [](#)
  This is some text inside of a div block.

- [Log in to Claude](https://claude.ai/login)
  Log in to Claude

  Log in to Claude

  [Download app](https://claude.ai/download)
  Download app

  Download app

# Making AI systems you can rely on

Anthropic is an AI safety and research company. We build reliable, interpretable, and steerable AI systems.

[Join us](https://www.anthropic.com/jobs)

Join us

Join us

## Our Purpose

We believe AI will have a vast impact on the world. Anthropic is dedicated to building systems that people can rely on and generating research about the opportunities and risks of AI.

- ### We Build Safer Systems

  We aim to build frontier AI systems that are reliable, interpretable, and steerable. We conduct frontier research, develop and apply a variety of safety techniques, and deploy the resulting systems via a set of partnerships and products.

- ### Safety Is a Science

  We treat AI safety as a systematic science, conducting research, applying it to our products, feeding those insights back into our research, and regularly sharing what we learn with the world along the way.

- ### Interdisciplinary

  Anthropic is a collaborative team of researchers, engineers, policy experts, business leaders and operators, who bring our experience from many different domains to our work.

- ### AI Companies are One Piece of a Big Puzzle

  AI has the potential to fundamentally change how the world works. We view ourselves as just one piece of this evolving puzzle. We collaborate with civil society, government, academia, nonprofits and industry to promote safety industry-wide.

## The Team

We’re a team of researchers, engineers, policy experts and operational leaders, with experience spanning a variety of disciplines, all working together to build reliable and understandable AI systems.

- 

  ### Research

  We conduct frontier AI research across a variety of modalities, and explore novel and emerging safety research areas from interpretability to RL from human feedback to policy and societal impacts analysis.

- 

  ### Policy

  We think about the impacts of our work and strive to communicate what we’re seeing at the frontier to policymakers and civil society in the US and abroad to help promote safe and reliable AI.

- 

  ### Product

  We translate our research into tangible, practical tools like Claude that benefit businesses, nonprofits and civil society groups and their clients and people around the globe.

- 

  ### Operations

  Our people, finance, legal, and recruiting teams are the human engines that make Anthropic go. We’ve had previous careers at NASA, startups, and the armed forces and our diverse experiences help make Anthropic a great place to work (and we love plants!).

## What we value and how we act

Every day, we make critical decisions that inform our ability to achieve our mission. Shaping the future of AI and, in turn, the future of our world is a responsibility and a privilege. Our values guide how we work together, the decisions we make, and ultimately how we show up for each other and work toward our mission.

1.  01

    ### Act for the global good.

    We strive to make decisions that maximize positive outcomes for humanity in the long run. This means we’re willing to be very bold in the actions we take to ensure our technology is a robustly positive force for good. We take seriously the task of safely guiding the world through a technological revolution that has the potential to change the course of human history, and are committed to helping make this transition go well.

2.  02

    ### Hold light and shade.

    AI has the potential to pose unprecedented risks to humanity if things go badly. It also has the potential to create unprecedented benefits for humanity if things go well. We need shade to understand and protect against the potential for bad outcomes. We need light to realize the good outcomes.

3.  03

    ### Be good to our users.

    At Anthropic, we define “users” broadly. Users are our customers, policy-makers, Ants, and anyone impacted by the technology we build or the actions we take. We cultivate generosity and kindness in all our interactions—with each other, with our users, and with the world at large. Going above and beyond for each other, our customers, and all of the people affected by our technology is meeting expectations.

4.  04

    ### Ignite a race to the top on safety.

    As a safety-first company, we believe that building reliable, trustworthy, and secure systems is our collective responsibility - and the market agrees. We work to inspire a ‘race to the top’ dynamic where AI developers must compete to develop the most safe and secure AI systems. We want to constantly set the industry bar for AI safety and security and drive others to do the same.

5.  05

    ### Do the simple thing that works.

    We take an empirical approach to problems and care about the size of our impact and not the sophistication of our methods. This doesn’t mean we throw together haphazard solutions. It means we try to identify the simplest solution and iterate from there. We don’t invent a spaceship if all we need is a bicycle.

6.  06

    ### Be helpful, honest, and harmless.

    Anthropic is a high-trust, low-ego organization. We communicate kindly and directly, assuming good intentions even in disagreement. We are thoughtful about our actions, avoiding harm and repairing relationships when needed. Everyone contributes, regardless of role. If something urgently needs to be done, the right person to do it is probably you!

7.  07

    ### Put the mission first.

    At the end of the day, the mission is what we’re all here for. It gives us a shared purpose and allows us to act swiftly together, rather than being pulled in multiple directions by competing goals. It engenders trust and collaboration and is the final arbiter in our decisions. When it comes to our mission, none of us are bystanders. We each take personal ownership over making our mission successful.

## Governance

Anthropic is a Public Benefit Corporation, whose purpose is the responsible development and maintenance of advanced AI for the long-term benefit of humanity. Our Board of Directors is elected by stockholders and our Long-Term Benefit Trust, as explained [here](https://www.anthropic.com/news/the-long-term-benefit-trust). Current members of the Board and the Long-Term Benefit Trust (LTBT) are listed below.

**Anthropic Board of Directors**\
Dario Amodei, Daniela Amodei, Yasmin Razavi, Jay Kreps, and Reed Hastings.

**LTBT Trustees**\
Neil Buddy Shah, Kanika Bahl, Zach Robinson, and Richard Fontaine.

Want to help us build the future of safe AI?

[Join us](https://www.anthropic.com/jobs)

Join us

Join us

## Footer

© 2025 Anthropic PBC

- [](https://www.linkedin.com/company/anthropicresearch)
- [](https://x.com/AnthropicAI)
- [](https://www.youtube.com/@anthropic-ai)

### Products

- [](https://claude.com/product/overview)
  Claude
- [](https://claude.com/product/claude-code)
  Claude Code
- [](https://claude.com/product/cowork)
  Cowork
- [](https://claude.com/chrome)
  Claude in Chrome
- [](https://claude.com/claude-in-excel)
  Claude in Excel
- [](https://claude.com/claude-in-powerpoint)
  Claude in PowerPoint
- [](https://claude.com/claude-in-slack)
  Claude in Slack
- [](https://www.claude.com/skills)
  Skills
- [](https://claude.com/pricing/max)
  Max plan
- [](https://claude.com/pricing/team)
  Team plan
- [](https://claude.com/pricing/enterprise)
  Enterprise plan
- [](https://claude.com/download)
  Download app
- [](https://claude.com/pricing)
  Pricing
- [](https://claude.ai/login)
  Log in to Claude

### Models

- [](https://www.anthropic.com/claude/opus)
  Opus
- [](https://www.anthropic.com/claude/sonnet)
  Sonnet
- [](https://www.anthropic.com/claude/haiku)
  Haiku

### Solutions

- [](https://claude.com/solutions/agents)
  AI agents
- [](https://claude.com/solutions/code-modernization)
  Code modernization
- [](https://claude.com/solutions/coding)
  Coding
- [](https://claude.com/solutions/customer-support)
  Customer support
- [](https://claude.com/solutions/education)
  Education
- [](https://claude.com/solutions/financial-services)
  Financial services
- [](https://claude.com/solutions/government)
  Government
- [](https://claude.com/solutions/healthcare)
  Healthcare
- [](https://claude.com/solutions/life-sciences)
  Life sciences
- [](https://claude.com/solutions/nonprofits)
  Nonprofits

### Claude Developer Platform

- [](http://claude.com/platform/api)
  Overview
- [](https://platform.claude.com/docs)
  Developer docs
- [](https://claude.com/pricing#api)
  Pricing
- [](https://claude.com/regional-compliance)
  Regional Compliance
- [](https://claude.com/partners/amazon-bedrock)
  Amazon Bedrock
- [](https://claude.com/partners/google-cloud-vertex-ai)
  Google Cloud’s Vertex AI
- [](https://platform.claude.com/)
  Console login

### Learn

- [](https://www.claude.com/blog)
  Blog
- [](https://claude.com/partners)
  Claude partner network
- [](https://claude.com/partners/mcp)
  Connectors
- [](https://www.anthropic.com/learn)
  Courses
- [](https://www.claude.com/customers)
  Customer stories
- [](https://www.anthropic.com/engineering)
  Engineering at Anthropic
- [](https://www.anthropic.com/events)
  Events
- [](https://claude.com/plugins)
  Plugins
- [](https://claude.com/partners/powered-by-claude)
  Powered by Claude
- [](https://claude.com/partners/services)
  Service partners
- [](https://claude.com/programs/startups)
  Startups program
- [](https://claude.com/resources/tutorials)
  Tutorials
- [](https://claude.com/resources/use-cases)
  Use cases

### Company

- [](https://www.anthropic.com/company)
  Anthropic
- [](https://www.anthropic.com/careers)
  Careers
- [](https://www.anthropic.com/economic-futures)
  Economic Futures
- [](https://www.anthropic.com/research)
  Research
- [](https://www.anthropic.com/news)
  News
- [](https://www.anthropic.com/constitution)
  Claude's Constitution
- [](https://www.anthropic.com/responsible-scaling-policy)
  Responsible Scaling Policy
- [](https://trust.anthropic.com/)
  Security and compliance
- [](https://www.anthropic.com/transparency)
  Transparency

### Help and security

- [](https://www.anthropic.com/supported-countries)
  Availability
- [](https://status.anthropic.com/)
  Status
- [](https://support.claude.com/)
  Support center

### Terms and policies

Privacy choices

### Cookie Settings

We use cookies to deliver and improve our services, analyze site usage, and if you agree, to customize or personalize your experience and market our services to you. You can read our Cookie Policy [here](https://www.anthropic.com/legal/cookies).

Customize cookie settings

Reject all cookies

Accept all cookies

###### Necessary

Enables security and basic functionality.

Required

###### Analytics

Enables tracking of site performance.

Off

###### Marketing

Enables ads personalization and tracking.

Off

Save preferences

[](https://www.anthropic.com/legal/privacy)

Privacy policy

[](https://www.anthropic.com/legal/consumer-health-data-privacy-policy)

Consumer health data privacy policy

[](https://www.anthropic.com/responsible-disclosure-policy)

Responsible disclosure policy

[](https://www.anthropic.com/legal/commercial-terms)

Terms of service: Commercial

[](https://www.anthropic.com/legal/consumer-terms)

Terms of service: Consumer

[](https://www.anthropic.com/legal/aup)

Usage policy

© 2024 Anthropic PBC

- [](https://www.youtube.com/@anthropic-ai)
- [](https://www.linkedin.com/company/anthropicresearch)
- [](https://x.com/AnthropicAI)
