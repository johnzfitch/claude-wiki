---
category: "19-Reference"
fetched_at: "2026-02-08T23:10:02Z"
source_url: "https://www.anthropic.com/news/anthropic-s-response-to-governor-newsom-s-ai-working-group-draft-report"
title: "Anthropic’s response to Governor Newsom’s AI working group draft report \\ Anthropic"
---

Societal Impacts

# Anthropic’s response to Governor Newsom’s AI working group draft report

Mar 19, 2025

This week, the California Governor’s [Working Group on AI Frontier Models](https://www.cafrontieraigov.org/) released its draft report. We agree with the working group’s focus on the need for [objective standards](https://www.anthropic.com/news/an-ai-policy-tool-for-today-ambitiously-invest-in-nist) and evidence-based policy guidance, and especially its emphasis on transparency as a means to create a well functioning AI policy environment.  
  
When done thoughtfully, transparency can be a low-cost, high-impact means of growing the evidence base around a new technology, increasing consumer trust, and causing companies to enter into positive-sum competitions with one another. We welcome greater discussion of how frontier labs should be transparent about their AI development practices and were glad to see the working group emphasize this - in particular, we appreciated the focus on the need for labs to disclose how they secure their models from theft, and how they test their models for potential national security risks.  
  
Many of the report’s recommendations already reflect industry best practices which Anthropic adheres to: for example Anthropic’s [Responsible Scaling Policy](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy) publicly lays out how we assess our models for misuse and autonomy risks and thresholds that trigger increased safety and security measures for us. We also publicly describe the results of our safety and security testing as part of each major model release, and perform [third-party testing](https://www.anthropic.com/news/third-party-testing) to augment our own internal tests. Many other frontier AI companies have similar practices.  
  
In line with the report’s findings, we believe governments could play a constructive role in improving transparency in the safety and security practices of frontier AI companies. At present frontier AI companies are not *required* to have a safety and security policy (even one entirely of their choice), nor to describe it publicly, nor to publicly document the tests they run – and therefore not all companies do. We believe this could be done in a [light-touch way](https://www.anthropic.com/news/the-case-for-targeted-regulation) that does not impede innovation. As we wrote in our [recent policy submission to the White House](https://www.anthropic.com/news/anthropic-s-recommendations-ostp-u-s-ai-action-plan), we believe powerful AI systems will arrive soon - perhaps as early as the end of 2026 - so it is important we all devote effort to building a policy regime that creates greater transparency about the safety and security protocols of how AI systems are built.  
  
The Working Group has also highlighted areas where academia, civil society, and industry will need to apply more focus in the coming years - particularly on the economic impacts of AI, where Anthropic is today trying to contribute via [our Economic Index](https://www.anthropic.com/news/the-anthropic-economic-index). We look forward to providing further feedback to the working group to aid and inform the work of finalizing the report. We commend the Governor for his foresight in kicking off this conversation, and we look forward to helping shape California’s approach to frontier model safety.

[](https://twitter.com/intent/tweet?text=https://www.anthropic.com/news/anthropic-s-response-to-governor-newsom-s-ai-working-group-draft-report)[](https://www.linkedin.com/shareArticle?mini=true&url=https://www.anthropic.com/news/anthropic-s-response-to-governor-newsom-s-ai-working-group-draft-report)

## Related content

### Introducing Claude Opus 4.6

We’re upgrading our smartest model. Across agentic coding, computer use, tool use, search, and finance, Opus 4.6 is an industry-leading model, often by wide margin.

[Read more](/news/claude-opus-4-6)

### Claude is a space to think

We’ve made a choice: Claude will remain ad-free. We explain why advertising incentives are incompatible with a genuinely helpful AI assistant, and how we plan to expand access without compromising user trust.

[Read more](/news/claude-is-a-space-to-think)

### Apple’s Xcode now supports the Claude Agent SDK

[Read more](/news/apple-xcode-claude-agent-sdk)
